node_lines:
- node_line_name: pre_retrieve_node_line
  nodes:
    - node_type: query_expansion
      strategy:
        metrics: [retrieval_f1, retrieval_ndcg, retrieval_map]
        speed_threshold: 10
        top_k: 10
        retrieval_modules:
          - module_type: bm25
#            bm25_tokenizer: ko_kiwi
          - module_type: vectordb
            embedding_model: openai
      modules:
        - module_type: pass_query_expansion
        - module_type: query_decompose
          generator_module_type: llama_index_llm
          llm: openai
          model: gpt-4o-mini
          temperature: [ 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0 ]
        - module_type: hyde
          generator_module_type: llama_index_llm
          llm: openai
          model: gpt-4o-mini
          max_token: 64
- node_line_name: retrieve_node_line
  nodes:
    - node_type: retrieval
      strategy:
        metrics: [retrieval_f1, retrieval_map, retrieval_ndcg]
      top_k: 4
      modules:
        - module_type: bm25
#          bm25_tokenizer: ko_kiwi
        - module_type: vectordb
          embedding_model: openai
        - module_type: hybrid_rrf
          weight_range: (3, 5)
        - module_type: hybrid_cc
          normalize_method: [ mm, tmm, z, dbsf ]
          weight_range: (0.0, 1.0)
          test_weight_size: 11
    - node_type: passage_reranker
      strategy:
        metrics: [retrieval_f1, retrieval_map, retrieval_ndcg]
      top_k: 3
      modules:
        - module_type: pass_reranker
        - module_type: koreranker
        - module_type: upr
        - module_type: tart
        - module_type: cohere_reranker
          api_key: 43RtNTRhGHl1NloaInNhVQpByw5hyuSSqwcf17Gc
          batch: 64
          model: rerank-multilingual-v2.0
- node_line_name: post_retrieve_node_line
  nodes:
    - node_type: prompt_maker
      strategy:
        metrics:
          - metric_name: rouge
          - metric_name: sem_score
            embedding_model: openai
          - metric_name: bert_score
            lang: ko
        generator_modules:
          - module_type: llama_index_llm
            llm: openai
            model: gpt-4o-mini
            batch: 2
      modules:
        - module_type: fstring
          prompt: ["주어진 단락만을 이용하여 질문에 따라 답하시오. 단락: {retrieved_contents} \n\n 질문: {query} \n\n 답변:",
                   "단락을 읽고 질문에 답하세요. 답할때 단계별로 천천히 잘 생각하여 답변하세요. 반드시 단락 내용을 기반으로 말하고 거짓을 말하지 마세요. 단락: {retrieved_contents} \n\n 질문: {query} \n\n 답변:"]
        - module_type: long_context_reorder
          prompt: [ "주어진 단락만을 이용하여 질문에 따라 답하시오. 단락: {retrieved_contents} \n\n 질문: {query} \n\n 답변:",
                    "단락을 읽고 질문에 답하세요. 답할때 단계별로 천천히 잘 생각하여 답변하세요. 반드시 단락 내용을 기반으로 말하고 거짓을 말하지 마세요. 단락: {retrieved_contents} \n\n 질문: {query} \n\n 답변:" ]
    - node_type: generator
      strategy:
        metrics:
          - metric_name: rouge
          - metric_name: sem_score
            embedding_model: openai
          - metric_name: bert_score
            lang: ko
#            - metric_name: g_eval
      modules:
        - module_type: openai_llm
          llm: gpt-4o-mini
          temperature: [ 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0 ]
          batch: 2